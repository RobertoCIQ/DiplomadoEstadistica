# -*- coding: utf-8 -*-
"""Alexis Data Challenge..ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TwUEWCSXx28GdsgAoyZmqE92LeUgN2z0
"""

import pandas as pd
import numpy as np

df = pd.read_csv("/content/car_price_prediction.csv")
df.head(5)

# Clean 'Engine Volume' by extracting only the numeric part and converting to float
df["Engine volume"] = df["Engine volume"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
df["Engine volume"] = pd.to_numeric(df["Engine volume"], errors='coerce')

df["Doors"] = df["Doors"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
df["Doors"] = pd.to_numeric(df["Doors"], errors='coerce')

df["Mileage"] = df["Mileage"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
df["Mileage"] = pd.to_numeric(df["Mileage"], errors='coerce')

# Quitamos el outlier principal
max_price_index = df['Price'].idxmax()
df = df.drop(max_price_index).reset_index(drop=True)

max_price_index = df['Engine volume'].idxmax()
df = df.drop(max_price_index).reset_index(drop=True)

display(df.head())
df.info()

mean_price = df['Price'].mean()
std_price = df['Price'].std()
upper_bound = mean_price + (3 * std_price)

df = df[df['Price'] < upper_bound]

print(f"Mean Price: {mean_price:,.2f}")
print(f"Standard Deviation of Price: {std_price:,.2f}")
print(f"Upper bound for outliers (Mean + 3*Std Dev): {upper_bound:,.2f}")
print(f"New number of rows after outlier removal: {df.shape[0]}")


display(df.head())
df.info()

for column in df.columns:
    print(column, len(df[column].unique()))

# Clean Levy column first: replace '-' with 0 and convert to integer
df['Levy'] = df['Levy'].replace('-', 0).astype(int)

df_encoded2 = df

columns_to_dummy = ['Manufacturer','Model','Gear box type',"Category" ,'Leather interior', 'Fuel type', 'Drive wheels', 'Wheel']

# Apply one-hot encoding to the specified columns
df_encoded2 = pd.get_dummies(df, columns=columns_to_dummy, drop_first=True)

# Drop the 'Color' column
df_encoded2 = df_encoded2.drop(columns=['Color'])
#df_encoded2 = df_encoded2.drop(columns=columns_to_dummy)
display(df_encoded2.head())
df_encoded2.info()

print("El promedio es", df["Price"].mean())

#correlation_matrix = df_encoded2.corr(numeric_only=True)
#display(correlation_matrix)

# import seaborn as sns
# import matplotlib.pyplot as plt

# plt.figure(figsize=(10,8))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
# plt.title('Matriz de Correlaci칩n de Variables Num칠ricas')
# plt.show()



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np

# --- 1. CONFIGURACI칍N INICIAL (Reutilizando la preparaci칩n de datos anterior) ---
df_encoded = df_encoded2

y = df_encoded['Price']
features_to_exclude = ['ID', 'Price']
X_raw = df_encoded.drop(columns=features_to_exclude)



# --- 3. CODIFICACI칍N ONE-HOT PARA EL RESTO DE VARIABLES CATEG칍RICAS ---

# Aplicar One-Hot Encoding solo a las categ칩ric tes (baja cardinalidad)
# X_final = pd.get_dummies(X_encoded, columns=other_categorical_cols, drop_first=True)

print(f"N칰mero original de features: {X_raw.shape[1]}")
print("---")

# --- 4. DIVISI칍N Y ENTRENAMIENTO DEL MODELO DE REGRESI칍N ---
# X_final ahora contiene las features listas para el modelo.

X_train, X_test, y_train, y_test = train_test_split(
    X_raw,
    y,
    test_size=0.2,
    random_state=42
)


print(f"Tama침o de Entrenamiento (X): {X_train.shape}")
print(f"Tama침o de Prueba (X): {X_test.shape}")
print("---")

# 4. Inicializaci칩n y Entrenamiento del Modelo
# Utilizaremos una profundidad limitada (max_depth=10) para control.
tree_regressor = DecisionTreeRegressor()
tree_regressor.fit(X_train, y_train)

print("Modelo de 츼rbol de Regresi칩n Entrenado Correctamente con todas las columnas.")
print("---")

# 5. Evaluaci칩n del Modelo
y_pred = tree_regressor.predict(X_test)

# C치lculo de m칠tricas
mae= mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mse)

print("--- Resultados de Evaluaci칩n de Regresi칩n ---")
print(f"Mean Absolute Error (MAE): {mae:,.2f}")
print(f"Error Cuadr치tico Medio (MSE): {mse:,.2f}")
print(f"Ra칤z del Error Cuadr치tico Medio (RMSE): {rmse:,.2f}")
print(f"Coeficiente de Determinaci칩n (R^2): {r2:.4f}")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# import numpy as np
# 
# st.title("游늳 Dashboard de Precios de Autom칩viles")
# 
# # --- 1. Carga y preprocesamiento de datos ---
# # Cargamos el dataset original
# df = pd.read_csv("car_price_prediction.csv")
# 
# # Limpieza de columnas espec칤fica
# df["Engine volume"] = df["Engine volume"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
# df["Engine volume"] = pd.to_numeric(df["Engine volume"], errors='coerce')
# 
# df["Doors"] = df["Doors"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
# df["Doors"] = pd.to_numeric(df["Doors"], errors='coerce')
# 
# df["Mileage"] = df["Mileage"].astype(str).str.extract('(\\d+\\.?\\d*)', expand=False)
# df["Mileage"] = pd.to_numeric(df["Mileage"], errors='coerce')
# 
# # Limpiar columna Levy: reemplazar '-' con 0 y convertir a entero
# df['Levy'] = df['Levy'].replace('-', 0).astype(int)
# 
# # Eliminar outliers principales (como se hizo en el notebook)
# max_price_index = df['Price'].idxmax()
# df = df.drop(max_price_index).reset_index(drop=True)
# 
# # El outlier de Engine volume fue un valor maximo que probablemente era un error.
# # Para el dashboard, simplemente nos aseguraremos de que no haya nulos y los trataremos si fuera necesario.
# # En este caso, ya est치n tratados por pd.to_numeric(errors='coerce')
# 
# # Eliminaci칩n de outliers de 'Price' usando 3 desviaciones est치ndar (como se hizo en el notebook)
# mean_price = df['Price'].mean()
# std_price = df['Price'].std()
# upper_bound = mean_price + (3 * std_price)
# df = df[df['Price'] < upper_bound]
# 
# # --- 2. KPIs ---
# col1, col2, col3 = st.columns(3)
# col1.metric("Total de Veh칤culos", f"{df.shape[0]:,}")
# col2.metric("Precio Promedio", f"${df['Price'].mean():,.0f}")
# col3.metric("Fabricantes 칔nicos", f"{df['Manufacturer'].nunique()}")
# 
# # --- 3. Gr치ficas ---
# # Gr치fica de distribuci칩n de precios
# fig_price_dist = px.histogram(df, x="Price", nbins=50, title="Distribuci칩n de Precios de Veh칤culos")
# st.plotly_chart(fig_price_dist)
# 
# # Gr치fica de precio promedio por categor칤a
# avg_price_by_category = df.groupby('Category')['Price'].mean().reset_index()
# fig_avg_price_category = px.bar(
#     avg_price_by_category,
#     x="Category",
#     y="Price",
#     title="Precio Promedio por Categor칤a",
#     labels={"Price": "Precio Promedio", "Category": "Categor칤a"},
#     template="plotly_white"
# )
# st.plotly_chart(fig_avg_price_category)
# 
# # Gr치fica de precio promedio por fabricante (top 10)
# avg_price_by_manufacturer = df.groupby('Manufacturer')['Price'].mean().sort_values(ascending=False).head(10).reset_index()
# fig_avg_price_manufacturer = px.bar(
#     avg_price_by_manufacturer,
#     x="Manufacturer",
#     y="Price",
#     title="Top 10 Fabricantes por Precio Promedio",
#     labels={"Price": "Precio Promedio", "Manufacturer": "Fabricante"},
#     template="plotly_white"
# )
# st.plotly_chart(fig_avg_price_manufacturer)
#